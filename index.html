<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">

<html>

<head>
    <meta charset="UTF-8">
  <meta name=viewport content="width=800">
  <meta name="generator" content="HTML Tidy for Linux/x86 (vers 11 February 2007), see www.w3.org">
  <style type="text/css">
    /* Color scheme stolen from Sergey Karayev */
    a {
      color: #1478dd;
      text-decoration: none;
    }
    
    a:focus,
    a:hover {
      color: #f09228;
      text-decoration: none;
    }
    
    body,
    td,
    th,
    tr,
    p,
    a {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 14px
    }
    
    strong {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 14px;
    }
    
    heading {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 22px;
    }
    
    papertitle {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 14px;
      font-weight: 700
    }
    
    name {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 32px;
    }
    
    .one {
      width: 160px;
      height: 160px;
      position: relative;
    }
    
    .two {
      width: 160px;
      height: 160px;
      position: absolute;
      transition: opacity .2s ease-in-out;
      -moz-transition: opacity .2s ease-in-out;
      -webkit-transition: opacity .2s ease-in-out;
    }
    
    .fade {
      transition: opacity .2s ease-in-out;
      -moz-transition: opacity .2s ease-in-out;
      -webkit-transition: opacity .2s ease-in-out;
    }
	  
    
    span.highlight {
      background-color: #ffffd0;
    }

    .project-table {
        width: 95%;
        border-collapse: collapse;
        border-bottom: 1px solid black; /* Add a line at the bottom */
    }

    .project-table td {
        padding: 20px;
        width: 50%;
        vertical-align: middle;
        border: none; /* Remove cell borders */
    }

    .project-image {
        width: 100%; /* Fit width of the cell */
        height: auto; /* Maintain aspect ratio */
    }

  </style>
  <link rel="icon" type="image/jpg" href="images/icon.jpg">
  <title>Tan-Hanh Pham</title>
  <meta http-equiv="Content-Type" content="text/html; charset=us-ascii">
  <link href='https://fonts.googleapis.com/css?family=Lato:400,700,400italic,700italic' rel='stylesheet' type='text/css'>
</head>

<body>
  <table width="800" border="0" align="center" cellspacing="0" cellpadding="0">
    <tr>
      <td>
        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr>
            <td width="67%" valign="middle">
              <p align="center">
                <name><b>Tan-Hanh Pham</b></name>
              </p>
              <p> I am a second-year Ph.D student at <a href="https://www.fit.edu/">Florida Institute of Technology</a>, where I work on Machine Learning, Computer Vision, Generative models, and LLMs Applications.
              </p>
              <p>
                Previously, I was a research assistant at <a href="http://bimil.konkuk.ac.kr/"> Bioinspired System Laboratory</a>. I received my Master of Science degree in Smart Vehicle Engineering from 
                <a href="https://english.kku.ac.kr/mbshome/mbs/wwwen/index.do">Konkuk University</a>, South Korea, in 2022. Following that, I spent half a year doing my post-master at the <a href="http://bimil.konkuk.ac.kr/">Bioinspired System Laboratory</a>.
              </p>
			  

  
              <p align=center>
		            <!-- <a href="data/Hanh_Master_Thesis.pdf">Master Thesis</a> &nbsp/&nbsp -->
                <a href="https://www.overleaf.com/read/tgtvcsncdrvr#ff0a9b">CV</a> &nbsp/&nbsp
                <a href="https://scholar.google.com/citations?user=G-12obIAAAAJ&hl=en">Google Scholar</a> &nbsp/&nbsp
                <a href="https://github.com/Hanhpt23/">GitHub</a> &nbsp/&nbsp
                <a href="https://www.linkedin.com/in/hanhtanpham/">LinkedIn</a> 
              </p>
            </td>
            <td width="33%">
              <img src="images/Hanh.jpg" style="width:100%;max-width:100%;object-fit: cover; border-radius: 50%;">
            </td>
          </tr>
         </table>

        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr>
            <td width="100%" valign="middle">
              <heading>Research Interests</heading>
              <p>
                My research interests include Machine Learning, Deep Learning, Computer Vision, and LLMs, especially their applications in Medical Imaging Diagnosis and Agriculture Precision. Please check my latest publications <a href="https://scholar.google.com/citations?user=G-12obIAAAAJ&hl=en">here</a>.

            </p>    
		    
		    <p style="color:rgb(0, 0, 0)">I am happy to collaborate with you in AI related projects. Please kindly send me an email (hanhpt.phamtan@gmail.com). </p>

		   
		  </td>
          </tr>
	 </table>
	
			
							   
	    <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
	          <tr>
	            <td width="100%" valign="middle">
	 
			    <heading>Awards and Honors </heading>
	
			    <p>
			        <span>&#x25cf;</span> &nbsp; <b>[Mar. 2024]</b> &nbsp; The College's Award for Outstanding Graduate Student of the Year, Florida Tech, 2023.
			    </p>
	            <p>    
	                <span>&#x25cf;</span> &nbsp;  <b>[Jan. 2023]</b> &nbsp;  Ph.D. Fellowship funded by the USDA National Institute of Food and Agriculture, USA.
	             </p>
	             
	            <p>    
	                <span>&#x25cf;</span> &nbsp;  <b>[Apr. 2022]</b> &nbsp; Best Paper Award at the 18th International Conference on Intelligent Unmanned Systems (ICIUS) at Tokushima University, Japan, 2022. 
	            </p>
			    <p>    
			        <span>&#x25cf;</span> &nbsp; <b>[Sep. 2020]</b> &nbsp; Master Scholarship funded by the National Research Foundation of Korea (NRF) grant, South Korea.
	            </p>
			    <p>    
			        <span>&#x25cf;</span> &nbsp; <b>[Mar. 2019]</b> &nbsp; Certificate of Merit awarded for graduating sooner than the nominal duration at Ho Chi Minh City University of Technology and Education.
	            </p>
	            </td>
	          </tr>
		</table>			   
	
	     
	    <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
	          <tr>
	            <td width="100%" valign="middle">
	              <heading>Professional Activities</heading>
			    <p>    
			   <span>&#x25cf;</span> &nbsp;  <b>Reviewer</b>,   Scientific Reports - Nature
			</p>
			      <p>    
			   <span>&#x25cf;</span> &nbsp;  <b>Reviewer</b>,   2022 IEEE 3rd International Conference on Human Machine Systems (ICHMS)
			</p>
			 <!-- <script type="text/javascript" id="clustrmaps" src="//clustrmaps.com/map_v2.js?d=uQn9mqt0RNPQvGfcqXOyki1-J-ggyEsg10vRJ--LrfI&cl=ffffff&w=a"></script> -->
	
	            </td>
	          </tr>
		</table>					   
		




	      
	  <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr>
            <td>
              <heading>Publications</heading> 
              <h3>Journal Papers</h3>

            <p>
                <span>&#x25cf;</span> &nbsp; <b>[Apr. 2024]</b> &nbsp; 
                <strong>Pham, T.H.</strong> and Nguyen, K.D., 2024. <a href="https://doi.org/10.3390/make6020035"><papertitle>Soil Sampling Map Optimization with a Dual Deep Learning Framework.</papertitle></a> 
                    Machine Learning and Knowledge Extraction, 6(2), pp.751-769. 
                    <a href="https://doi.org/10.3390/make6020035"> DOI</a>
            </p> 

            <p>
                <span>&#x25cf;</span> &nbsp; <b>[Feb. 2024]</b> &nbsp; 
                <strong>Pham, T.H.</strong> and Nguyen, K.D., 2023. <a href="https://doi.org/10.48550/arXiv.2402.15909"><papertitle>Enhanced Droplet Analysis Using Generative Adversarial Networks.</papertitle></a> 
                    
                    <a href="https://doi.org/10.48550/arXiv.2402.15909"> arXiv</a>
            </p>  

		    <p>
			<span>&#x25cf;</span> &nbsp; <b>[Jan. 2024]</b> &nbsp; 
                <strong>Pham, T.H.</strong>, Acharya, P., Bachina, S., Osterloh, K. and Nguyen, K.D., 2024. <a href="https://doi.org/10.1016/j.compag.2024.108650"><papertitle>Deep-learning framework for optimal selection of soil sampling sites.</papertitle></a>
                Computers and Electronics in Agriculture, 217, p.108650. 
                <a href="https://arxiv.org/pdf/2309.00974"> arXiv</a> /
                <a href="https://doi.org/10.1016/j.compag.2024.108650"> DOI</a>
 			</p> 

             <p>
                <span>&#x25cf;</span> &nbsp; <b>[Sep. 2023]</b> &nbsp; 
                <strong>Pham, T.H.</strong>, X Li, and Nguyen, K.D., 2023. <a href="https://doi.org/10.48550/arXiv.2310.09998"><papertitle>Seunet-trans: A simple yet effective unet-transformer model for medical image segmentation.</papertitle></a> 
                    
                    <a href="https://doi.org/10.48550/arXiv.2310.09998"> arXiv</a>
            </p> 

            <p>
                <span>&#x25cf;</span> &nbsp; <b>[Jan. 2023]</b> &nbsp; 
                <strong>Pham, T.H.</strong>, Nguyen, K. and Park, H.C., 2023. <a href="https://doi.org/10.3390/make6020035"><papertitle>A robotic fish capable of fast underwater swimming and water leaping with high Froude number.</papertitle></a> 
                    Ocean Engineering, 268, p.113512.
                    <a href="https://doi.org/10.1016/j.oceaneng.2022.113512">DOI</a>
            </p> 

            <p style="margin-top: 40px;"></p>
            <h3>Conference Papers</h3>
            <p>
                <span>&#x25cf;</span> &nbsp; <b>[Nov. 2022]</b> &nbsp; 
                Nguyen, K., <strong>Pham, T.H.</strong> and Park, H.C., 2022. <a href="https://www.dbpia.co.kr/Journal/articleDetail?nodeId=NODE11182069"><papertitle>Numerical investigation of hydrodynamics for a fish-like robot under undulatory forward swimming.</papertitle></a> 
                    대한기계학회 춘추학술대회, pp.861-861.
            </p> 
            <p>
                <span>&#x25cf;</span> &nbsp; <b>[Apr. 2021]</b> &nbsp; 
                <strong>Pham, T.H.</strong>, Phan, H.V. and Park, H.C., 2021. <a href="https://www.dbpia.co.kr/Journal/articleDetail?nodeId=NODE10555238"><papertitle>Design and test of a tail-beating propulsion system for the robotic flying fish.</papertitle></a> 
                    대한기계학회 춘추학술대회, pp.97-97.
            </p> 

            <p>
                <span>&#x25cf;</span> &nbsp; <b>[Nov. 2021]</b> &nbsp; 
                <strong>Pham, T.H.</strong>, and Park, H.C., 2021. <a href="https://www.dbpia.co.kr/Journal/articleDetail?nodeId=NODE10555238"><papertitle>Preliminary study for developing a flying-fish-mimicking swimming robot.</papertitle></a> 
                    대한기계학회 춘추학술대회, pp.559-562.

            </p> 


            </td>
          </tr>
        </table>
	      



        <table class="project-table" width="95%" align="center" border="0" cellspacing="0" cellpadding="20">
            <tr>
                <heading> &nbsp; &nbsp; Projects</heading>
                <p style="margin-top: 10px;"></p>
            </tr>

            <!-- Soil sampling Project -->
            <tr onmouseout="loss_stop()" onmouseover="loss_start()">
                <td style="vertical-align: top;">
                    <a href="https://doi.org/10.1016/j.compag.2024.108650">
                        <papertitle>Deep-learning framework for optimal selection of soil sampling sites</papertitle>
                    </a>
                    <!-- <br> <br> -->

                    <p style="text-align: justify;">This study addresses the challenge of selecting optimal soil sampling locations within agricultural fields by leveraging deep learning techniques. 
                        In this project, we utilize data from local farms, incorporating features such as aspect, flow accumulation, slope, NDVI, and yield for training. 
                        We propose two methods: one employing a convolutional neural network (CNN) and another based on a deep learning framework utilizing transformers and self-attention. 
                        Our framework achieves impressive results on the testing dataset, outperforming the CNN-based method significantly. 
                        This work not only introduces a novel approach to soil sampling but also lays the groundwork for applying data science and machine learning to other agricultural challenges.
                    </p>
                    <p style="text-align: justify;">This project is supported from <a href="https://portal.nifa.usda.gov/web/crisprojectpages/1028237-dsfas-ai-deep-learning-framework-for-optimal-selection-of-soil-sampling-sites.html"> USDA National Institute of Food and Agriculture, USA.</a></p>

                </td>

                <td style="text-align: center; vertical-align: top;">
                    <!-- <img src='images/self-attention.png' class="project-image"> -->
                    <!-- First Image -->
                    <div style="position: relative;">
                        <img src='images/Soil_sampling_tool.png' class="project-image" style="position: relative; z-index: 1;">
                    </div>
                    <div style="font-size: 12px;">General pipeline of the soil sampling site selection tool using deep learning and thresholding techniques.</div>

                    <!-- Second Image -->
                    <div style="margin-top: 20px; position: relative;">
                        <img src='images/self-attention.png' class="project-image" style="position: relative; z-index: 1;">
                    </div>
                    <div style="font-size: 12px;">Self-attention mechanism.</div>
                </td>
            </tr>
        </table>
        

        <table class="project-table" width="95%" align="center" border="0" cellspacing="0" cellpadding="20">
            <!-- seUnet-Trans -->
            <tr onmouseout="loss_stop()" onmouseover="loss_start()">
                <td style="vertical-align: top;">
                    <a href="https://arxiv.org/pdf/2310.09998">
                        <papertitle>A Simple yet Effective UNet-Transformer Model for Medical Image Segmentation</papertitle>
                    </a>
                    <p style="text-align: justify;">In this project, we address the increasing importance of automated medical image segmentation in clinical practice, driven by the need for precise diagnosis and personalized treatment plans, alongside advancements in machine learning, notably deep learning. 
                        While CNNs have been dominant, Transformer-based models are gaining recognition for computer vision tasks. 
                        In this study, we propose a hybrid model, seUNet-Trans, combining UNet and Transformer architectures for medical image segmentation. 
                        In their approach, UNet serves as a feature extractor, followed by a bridge layer connecting UNet and Transformer sequentially. 
                        They employ pixel-level embedding without position embedding vectors to enhance efficiency and integrate spatial-reduction attention in the Transformer to reduce computational complexity. 
                        Extensive experimentation on seven medical image segmentation datasets, including polyp segmentation, demonstrates the superiority of our proposed seUNet-Trans network over several state-of-the-art models.
                    </p>
                </td>

                <td style="text-align: center; vertical-align: top;">
                    <!-- Insert Image 1 -->
                    <div style="margin-top: 20px; position: relative;">
                        <img src='images/UnetTransformer.png' class="project-image" style="position: relative; z-index: 1;">
                    </div>
                    <div style="font-size: 12px;">The architecture of our proposed method (seUNet-Trans).</div>

                    <!-- Insert Image 2 -->
                    <div style="margin-top: 20px; position: relative;">
                        <img src='images/GLAS.png' class="project-image" style="position: relative; z-index: 1;">
                    </div>
                    <div style="font-size: 12px;">The testing result on the <a href="https://paperswithcode.com/dataset/glas">Glas dataset.</a></div>
                </td>
            </tr>
        </table>


        <table class="project-table" width="95%" align="center" border="0" cellspacing="0" cellpadding="20">
            <!-- Droplet Project -->
            <tr onmouseout="loss_stop()" onmouseover="loss_start()">
                <td style="vertical-align: top;">
                    <a href="https://arxiv.org/html/2402.15909v1">
                        <papertitle>Enhanced Droplet Analysis Using Generative Adversarial Networks</papertitle>
                    </a>
                    <!-- <br> <br> -->

                    <p style="text-align: justify;">In this project, we explore the significance of precision devices in agriculture and the role of deep learning in enhancing their performance, specifically focusing on spray systems. 
                        Due to the limitations of collecting sufficient training data, the study proposes using generative adversarial networks (GANs) to create artificial images of droplets. 
                        By training the GAN model with a small dataset from high-speed cameras, it generates high-resolution images effectively. 
                        Leveraging these synthetic images, we proposed a droplet detection model that outperforms traditional methods, achieving a notable increase in mean average precision (mAP). 
                        This approach represents a pioneering use of generative models for augmenting droplet detection and contributes to addressing data scarcity challenges in precision agriculture, ultimately promoting efficient and sustainable agricultural practices.
                    </p>
                    <p style="text-align: justify;">This project is supported from <a href="https://portal.nifa.usda.gov/web/crisprojectpages/1029667-ai-enabled-droplet-tracking-for-crop-spraying-systems.html"> USDA National Institute of Food and Agriculture, USA.</a></p>
                </td>

                <td style="text-align: center; vertical-align: top;">
                    <!-- <img src='images/self-attention.png' class="project-image"> -->
                    <!-- First Image -->
                    <div style="position: relative;">
                        <img src='images/experiment_setup.png' class="project-image" style="position: relative; z-index: 1;">
                    </div>
                    <div style="font-size: 12px;">Eperimental setup of a spray system for droplet generation.</div>

                    <!-- Second Image -->
                    <div style="margin-top: 20px; position: relative;">
                        <img src='images/compare_prediction.png' class="project-image" style="position: relative; z-index: 1;">
                    </div>
                    <div style="font-size: 12px;">Droplet detection.</div>
                </td>
            </tr>
        </table>

        <table class="project-table" width="95%" align="center" border="0" cellspacing="0" cellpadding="20">
            <!-- 3D brain tumor segmentation -->
            <tr onmouseout="loss_stop()" onmouseover="loss_start()">
                <td style="vertical-align: top;">
                    <p style="font-weight: bold; color: #1478dd;"> CNN-Transformer based model for 3D Brain Tumor Segmentation</p>
                    
                    <!-- <a href="https://arxiv.org/html/2402.15909v1">
                        <papertitle>Enhanced Droplet Analysis Using Generative Adversarial Networks</papertitle>
                    </a> -->

                    <p style="text-align: justify;">In this paper, we introduce a novel methodology that combines convolutional neural networks (CNNs) and transformers to improve the accuracy of segmenting brain tumors in three-dimensional (3D) volumes. 
                        Our hybrid architecture utilizes CNNs for initial volume predictions and then transforms them into sequence-to-sequence segmentation predictions using transformers, aiming to enhance both accuracy and robustness while capturing global contextual information. 
                        The model is validated on a dataset from Harvard Medical School and Brats datasets, demonstrating effective segmentation of 3D brain tumors. 
                        We propose a promising avenue for advancing 3D brain tumor segmentation, contributing to the field of medical image analysis research. 
                        The source code is available on GitHub for further exploration.
                    </p>
                </td>

                <td style="text-align: center; vertical-align: top;">
                    <!-- First Image -->
                    <div style="margin-block: 20px; position: relative;">
                        <img src='images/3D-brain-tumor.png' class="project-image" style="position: relative; z-index: 1;">
                    </div>
                    <div style="font-size: 12px;">Using FreeView to visualize a brain volume which includes Flair and a brain tumor.</div>

                </td>
            </tr>
        </table>



				   
 
					   			    
					    
        </table>


	<table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr>
            <td>
              <br>
              <p align="right">
                <font size="1,5">
                  This webpage uses the template from <a href="https://jonbarron.info/">here</a>.
       
                  </font>
              </p>
            </td>
          </tr>
        </table>	
	
</body>
</html>		
							     
				     
							     
